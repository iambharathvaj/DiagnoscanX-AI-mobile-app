# -*- coding: utf-8 -*-
"""DiagnoscanX-Pneumonia_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HQJe_whLSGe9IXZObA6ptxXa5KpdxQfD

# **Pneumonia Detection using Transfer Learning**
"""

# importing all the required libraries and modules

import numpy as np
import os, random
import keras
import matplotlib.pyplot as plt
import tensorflow as tf
from keras.layers import Dense,GlobalAveragePooling2D
from keras.applications import InceptionV3
from keras.preprocessing import image
from keras.applications.inception_v3 import preprocess_input
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.optimizers import Adam
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report
import pickle

from google.colab import drive
drive.mount('/content/drive')

# Path of various directories
# Dataset : Chest X-Ray Images (Pneumonia) from Kaggle 

TRAIN_DIR = '/content/drive/My Drive/chest_xray/train'
TEST_DIR = '/content/drive/My Drive/chest_xray/test'
VAL_DIR = '/content/drive/My Drive/chest_xray/val'

pneumonia_train = '/content/drive/My Drive/chest_xray/train/PNEUMONIA'
normal_train = '/content/drive/My Drive/chest_xray/train/NORMAL'

pneumonia_test = '/content/drive/My Drive/chest_xray/test/PNEUMONIA'
normal_test = '/content/drive/My Drive/chest_xray/test/NORMAL'

pneumonia_val = '/content/drive/My Drive/chest_xray/val/PNEUMONIA'
normal_val = '/content/drive/My Drive/chest_xray/val/NORMAL'

"""### **Sample images from the dataset**"""

# Normal 
img_normal = plt.imread(f'{TRAIN_DIR}/NORMAL/IM-0117-0001.jpeg')
# Pneumonia
img_penumonia = plt.imread(f'{TRAIN_DIR}/PNEUMONIA/person1_bacteria_2.jpeg')

# Plot Configuration
plt.figure(figsize=(12, 5))
plt.subplot(1,3,1).set_title('Label: NORMAL')
plt.imshow(img_normal, cmap='gray')
plt.subplot(1,3,2).set_title('Label : PNEUMONIA')
plt.imshow(img_penumonia, cmap='gray')

plt.tight_layout()

"""# **Customizing the Inceptionv3 model**"""

base_model=InceptionV3(weights='imagenet',include_top=False, input_shape=(224,224,3)) #imports the inceptionv3 model 
# and slices off the top layer which is the one that classifies objects into various classes (we don't want this layer)

# Setting up the pre-trained weights of the inceptionv3 model as non-trainable
for layer in base_model.layers:
    layer.trainable=False       

# Adding new layers on top of the base model
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results
x=Dense(1024,activation='relu')(x) #dense layer 2
x=Dense(512,activation='relu')(x) #dense layer 3
preds=Dense(2,activation='softmax')(x) #final layer with softmax activation - here, we have only 2 classes (Pneumonia & Normal)

# Specify the inputs
# Specify the outputs
model=Model(inputs=base_model.inputs,outputs=preds)

# A new model has been created based on our architecture
model.summary()

# Name of all the layers in our new model which is built on top of the Inceptionv3 model (look at No. 311 till final layer)
for i,layer in enumerate(model.layers):
  print(i,layer.name)

"""## **Data Preparation**"""

def dir_file_count(directory):
  #Total number of files present inside the 'directory'
  return sum([len(files) for r, d, files in os.walk(directory)])

# Configuration parameters 
rescale = 1./255
target_size = (224, 224)
batch_size = 500            #Specifying the batch size
class_mode = 'categorical'

# Augment the training dataset images 
train_datagen = ImageDataGenerator(rescale=rescale,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   validation_split=0.2)
# Load the images in the generator 
train_generator = train_datagen.flow_from_directory(TRAIN_DIR,
                                                    target_size=target_size,
                                                    class_mode=class_mode,
                                                    batch_size=batch_size,
                                                    shuffle=True)
# Augment the validation dataset images
val_datagen = ImageDataGenerator(rescale=rescale)
# Load the images in the generator
val_generator = val_datagen.flow_from_directory(VAL_DIR, 
                                                target_size=target_size,
                                                class_mode=class_mode,
                                                batch_size=dir_file_count(VAL_DIR),
                                                shuffle=False)
# Augment the test dataset images
test_datagen = ImageDataGenerator(rescale=rescale)
# Load the images in the generator
test_generator = test_datagen.flow_from_directory(TEST_DIR,
                                                  target_size=target_size,
                                                  class_mode=class_mode,
                                                  batch_size=dir_file_count(TEST_DIR),
                                                  shuffle=False)

"""# **Training Process of our custom model**"""

model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])
# Adam optimizer
# Loss function will be categorical cross entropy
# Evaluation metric will be accuracy

# Start the training
history = model.fit_generator(train_generator,
                              steps_per_epoch=len(train_generator),
                              epochs=10,                                # Specifying the no. of epochs
                              validation_data=val_generator,
                              validation_steps=len(val_generator))

pickle.dump(model, open("ml-model-diagnoscanx-export.pkl","wb"))

"""# **Evaluation metrics (Performance)**"""

y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)
y_pred = y_pred.argmax(axis=-1)
y_true = test_generator.classes

precision = precision_score(y_true, y_pred) 
recall = recall_score(y_true, y_pred) 
f1 = f1_score(y_true, y_pred) 

print("-"*70)
print("Report")
print("-"*70)
print("%s%.2f%s"% ("Precision     : ", precision*100, "%"))
print("%s%.2f%s"% ("Recall        : ", recall*100,    "%"))
print("%s%.2f%s"% ("F1-Score      : ", f1*100,        "%"))
print("-"*70)
print("\n\n")

cls_report_print = classification_report(y_true, y_pred, target_names=['Pneumonia', 'Normal'])

cls_report = classification_report(y_true, y_pred, target_names=['Pneumonia', 'Normal'], output_dict=True)

print("-"*70)
print("Pneumonia Prediction")
print("-"*70)
print(cls_report_print)
print("-"*70)

"""# **Prediction**"""

# Obtaining the class labels from the testing dataset

class_names = sorted(test_generator.class_indices.items(), key=lambda pair:pair[1])
class_names = np.array([key.title() for key, value in class_names])
class_names

test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)
test_data = test_gen.flow_from_directory(str('/content/drive/My Drive/chest_xray/test'), target_size=(224,224))
for test_batch, test_label_batch in test_data:
  print("Image batch shape: ", test_batch.shape)
  print("Label batch shape: ", test_label_batch.shape)
  break

# Making Predictions on images from the testing dataset

predicted_batch = model.predict(test_batch)
predicted_id = np.argmax(predicted_batch, axis=-1)
predicted_label_batch = class_names[predicted_id]

label_id = np.argmax(test_label_batch, axis=-1)

# Plotting the images with their True label and Predicted label
# Checking whether the predictions are correct or wrong
plt.figure(figsize=(25,20))
plt.subplots_adjust(hspace=0.5)
for n in range(10,15):
  plt.subplot(6,5,n+1)
  plt.imshow(test_batch[n])
  color = "green" if predicted_id[n] == label_id[n] else "red"            # Correct: GREEN      #Incorrect: RED
  plt.title(predicted_label_batch[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model Predictions (Green: CORRECT, Red: INCORRECT)")